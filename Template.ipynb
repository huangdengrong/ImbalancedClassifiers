{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This Template is created to make grading fair and straightforward. Anything not in the place as mentioned in the template would not be graded.\n",
    "\n",
    "<font color='red'> # NOTE: We would run the notebook through a Plagiarism Checker. If it is found to be copied, your work would not be graded, and the incident would be highlighted to NYU Authorities. </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Library and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (100766, 48)\n",
      "Test dataset shape: (500, 47)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score,f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve,auc,precision_recall_curve,average_precision_score,make_scorer\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "#data = pd.read_csv(\"./qudditch_training.csv\")\n",
    "data = pd.read_csv(\"./leaderboard_training.csv\")\n",
    "test = pd.read_csv(\"./leaderboard_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART I: Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling missing values. (If ANY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Replace ? with NaN to handle missing values easily with pandas library\n",
    "data = data.replace('?',np.NaN)\n",
    "test = test.replace('?',np.NaN)\n",
    "\n",
    "## Drop columns with too many missing values\n",
    "data = data.drop(columns=['move_specialty','weight','player_code'])\n",
    "test = test.drop(columns=['move_specialty','weight','player_code'])\n",
    "\n",
    "## Drop columns unique to a player like id and player id_num\n",
    "data = data.drop(columns=['player_id','id_num'])\n",
    "test = test.drop(columns=['player_id','id_num'])\n",
    "\n",
    "## Set missing values in the house to Other\n",
    "data = data.fillna(value={'house':'Other'})\n",
    "test = test.fillna(value={'house':'Other'})\n",
    "\n",
    "## Set Unknown/Invalid gender to the most common gender Female\n",
    "data.loc[data.gender =='Unknown/Invalid', 'gender']=data['gender'].mode()[0]\n",
    "test.loc[test.gender =='Unknown/Invalid', 'gender']=test['gender'].mode()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Datatype Conversion From Numeric to categoric and Vice-versa. (If ANY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (100766, 121)\n"
     ]
    }
   ],
   "source": [
    "## Set label to 0-1 instead of No,Yes\n",
    "data['quidditch_league_player'] = data['quidditch_league_player'].replace({'NO': 0, 'YES': 1})\n",
    "\n",
    "## Binary encode gender information\n",
    "data['gender'] = data['gender'].replace({'Female': 1, 'Male': 0})\n",
    "test['gender'] = test['gender'].replace({'Female': 1, 'Male': 0})\n",
    "\n",
    "## One hot encode house information\n",
    "data = pd.concat([data,pd.get_dummies(data['house'], prefix='house',drop_first = True)],axis=1)\n",
    "data = data.drop('house',axis=1)\n",
    "test = pd.concat([test,pd.get_dummies(test['house'], prefix='house',drop_first = True)],axis=1)\n",
    "test = test.drop('house',axis=1)\n",
    "\n",
    "## One hot encode player type\n",
    "data = pd.concat([data,pd.get_dummies(data['player_type'], prefix='player_type',drop_first = True)],axis=1)\n",
    "data = data.drop('player_type',axis=1)\n",
    "test = pd.concat([test,pd.get_dummies(test['player_type'], prefix='player_type',drop_first = True)],axis=1)\n",
    "test = test.drop('player_type',axis=1)\n",
    "\n",
    "## One hot encode game_move_id\n",
    "data = pd.concat([data,pd.get_dummies(data['game_move_id'], prefix='game_move_id',drop_first = True)],axis=1)\n",
    "data = data.drop('game_move_id',axis=1)\n",
    "test = pd.concat([test,pd.get_dummies(test['game_move_id'], prefix='game_move_id',drop_first = True)],axis=1)\n",
    "test = test.drop('game_move_id',axis=1)\n",
    "\n",
    "## One hot encode penalty_id\n",
    "data = pd.concat([data,pd.get_dummies(data['penalty_id'], prefix='penalty_id',drop_first = True)],axis=1)\n",
    "data = data.drop('penalty_id',axis=1)\n",
    "test = pd.concat([test,pd.get_dummies(test['penalty_id'], prefix='penalty_id',drop_first = True)],axis=1)\n",
    "test = test.drop('penalty_id',axis=1)\n",
    "\n",
    "## One hot encode foul_type_id\n",
    "data = pd.concat([data,pd.get_dummies(data['foul_type_id'], prefix='foul_type_id',drop_first = True)],axis=1)\n",
    "data = data.drop('foul_type_id',axis=1)\n",
    "test = pd.concat([test,pd.get_dummies(test['foul_type_id'], prefix='foul_type_id',drop_first = True)],axis=1)\n",
    "test = test.drop('foul_type_id',axis=1)\n",
    "\n",
    "data['snitchnip'] = data['snitchnip'].replace({'>200': 2, '>300': 2, 'Norm': 1, 'None': 0})\n",
    "test['snitchnip'] = test['snitchnip'].replace({'>200': 2, '>300': 2, 'Norm': 1, 'None': 0})\n",
    "\n",
    "data['stooging'] = data['stooging'].replace({'>7': 2, '>8': 2, 'Norm': 1, 'None': 0})\n",
    "test['stooging'] = test['stooging'].replace({'>7': 2, '>8': 2, 'Norm': 1, 'None': 0})\n",
    "\n",
    "## Replace in the below attbs No with 1 and Steady,Up,Down as 1 as we thought of it as they are either there or not there.\n",
    "attbs = ['body_blow','checking','dopplebeater_defence','no_hands_tackle','sloth_grip_roll',\n",
    "       'twirl','spiral_dive','wronski_feint','zig-zag','porskoff_ploy','transylvanian_tackle' ,'woollongong_shimmy',\n",
    "       'power_play','starfish_and_stick','bludger_backbeat','hawkshead_attacking_formation','chelmondiston_charge',\n",
    "       'dionysus_dive','double_eight_loop','finbourgh_flick','reverse_pass','parkins_pincer','plumpton_pass']\n",
    "\n",
    "for col in attbs:\n",
    "    col_temp=col+'_temp'\n",
    "    data[col_temp] = data[col].apply(lambda x: 0 if (x=='No' or x=='Steady') else 1)\n",
    "    test[col_temp] = test[col].apply(lambda x: 0 if (x=='No' or x=='Steady') else 1)\n",
    "\n",
    "data[attbs] = data[attbs].replace({'No': 0, 'Steady': 1, 'Up': 1, 'Down': 1})\n",
    "test[attbs] = test[attbs].replace({'No': 0, 'Steady': 1, 'Up': 1, 'Down': 1})\n",
    "    \n",
    "## Replace Change and Snitch Count with their binary encoding\n",
    "data['change'] = data['change'].replace({'No': 0, 'Ch': 1})\n",
    "test['change'] = test['change'].replace({'No': 0, 'Ch': 1})\n",
    "\n",
    "data['snitch_caught'] = data['snitch_caught'].replace({'No': 0, 'Yes': 1})\n",
    "test['snitch_caught'] = test['snitch_caught'].replace({'No': 0, 'Yes': 1})\n",
    "print(\"Dataset shape:\", data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Reduction or extraction. (If ANY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>game_duration</th>\n",
       "      <th>num_game_moves</th>\n",
       "      <th>num_game_losses</th>\n",
       "      <th>num_practice_sessions</th>\n",
       "      <th>num_games_satout</th>\n",
       "      <th>num_games_injured</th>\n",
       "      <th>num_games_notpartof</th>\n",
       "      <th>num_games_won</th>\n",
       "      <th>snitchnip</th>\n",
       "      <th>stooging</th>\n",
       "      <th>change</th>\n",
       "      <th>snitch_caught</th>\n",
       "      <th>quidditch_league_player</th>\n",
       "      <th>house_Hufflepuff</th>\n",
       "      <th>house_Other</th>\n",
       "      <th>house_Ravenclaw</th>\n",
       "      <th>house_Slytherin</th>\n",
       "      <th>player_type_Beater2</th>\n",
       "      <th>player_type_Captain</th>\n",
       "      <th>player_type_Chaser1</th>\n",
       "      <th>player_type_Chaser2</th>\n",
       "      <th>player_type_Chaser3</th>\n",
       "      <th>player_type_Keeper</th>\n",
       "      <th>player_type_Multiple</th>\n",
       "      <th>player_type_Seeker</th>\n",
       "      <th>game_move_id_2</th>\n",
       "      <th>game_move_id_3</th>\n",
       "      <th>game_move_id_4</th>\n",
       "      <th>game_move_id_5</th>\n",
       "      <th>game_move_id_6</th>\n",
       "      <th>game_move_id_7</th>\n",
       "      <th>game_move_id_8</th>\n",
       "      <th>game_move_id_9</th>\n",
       "      <th>game_move_id_10</th>\n",
       "      <th>game_move_id_11</th>\n",
       "      <th>game_move_id_12</th>\n",
       "      <th>game_move_id_13</th>\n",
       "      <th>game_move_id_14</th>\n",
       "      <th>game_move_id_15</th>\n",
       "      <th>game_move_id_16</th>\n",
       "      <th>game_move_id_17</th>\n",
       "      <th>game_move_id_18</th>\n",
       "      <th>game_move_id_19</th>\n",
       "      <th>game_move_id_20</th>\n",
       "      <th>game_move_id_22</th>\n",
       "      <th>game_move_id_23</th>\n",
       "      <th>game_move_id_24</th>\n",
       "      <th>game_move_id_25</th>\n",
       "      <th>game_move_id_27</th>\n",
       "      <th>game_move_id_28</th>\n",
       "      <th>penalty_id_2</th>\n",
       "      <th>penalty_id_3</th>\n",
       "      <th>penalty_id_4</th>\n",
       "      <th>penalty_id_5</th>\n",
       "      <th>penalty_id_6</th>\n",
       "      <th>penalty_id_7</th>\n",
       "      <th>penalty_id_8</th>\n",
       "      <th>penalty_id_9</th>\n",
       "      <th>penalty_id_10</th>\n",
       "      <th>penalty_id_11</th>\n",
       "      <th>penalty_id_13</th>\n",
       "      <th>penalty_id_14</th>\n",
       "      <th>penalty_id_17</th>\n",
       "      <th>penalty_id_20</th>\n",
       "      <th>penalty_id_22</th>\n",
       "      <th>penalty_id_25</th>\n",
       "      <th>foul_type_id_2</th>\n",
       "      <th>foul_type_id_3</th>\n",
       "      <th>foul_type_id_4</th>\n",
       "      <th>foul_type_id_5</th>\n",
       "      <th>foul_type_id_6</th>\n",
       "      <th>foul_type_id_7</th>\n",
       "      <th>foul_type_id_8</th>\n",
       "      <th>num_games_notperformed</th>\n",
       "      <th>num_tac_changes</th>\n",
       "      <th>num_tac_used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender   age  game_duration  num_game_moves  num_game_losses  num_practice_sessions  num_games_satout  num_games_injured  num_games_notpartof  num_games_won  snitchnip  stooging  change  snitch_caught  quidditch_league_player  house_Hufflepuff  house_Other  house_Ravenclaw  house_Slytherin  player_type_Beater2  player_type_Captain  player_type_Chaser1  player_type_Chaser2  player_type_Chaser3  player_type_Keeper  player_type_Multiple  player_type_Seeker  game_move_id_2  game_move_id_3  game_move_id_4  game_move_id_5  game_move_id_6  game_move_id_7  game_move_id_8  game_move_id_9  game_move_id_10  game_move_id_11  game_move_id_12  game_move_id_13  game_move_id_14  game_move_id_15  game_move_id_16  game_move_id_17  game_move_id_18  game_move_id_19  game_move_id_20  game_move_id_22  game_move_id_23  game_move_id_24  game_move_id_25  game_move_id_27  game_move_id_28  penalty_id_2  penalty_id_3  penalty_id_4  penalty_id_5  penalty_id_6  penalty_id_7  penalty_id_8  penalty_id_9  \\\n",
       "0       1  11.0              1              41                0                      1                 0                  0                    0              1          0         0       0              0                        0                 0            0                0                0                    0                    0                    0                    0                    0                   0                     0                   0               0               0               0               0               0               0               0               0                0                0                0                0                0                0                0                0                0                0                0                0                0                0                1                0                0             0             0             0             0             0             0             0             0   \n",
       "1       1  12.0              3              59                0                     18                 0                  0                    0              9          0         0       1              1                        0                 0            0                0                0                    0                    0                    0                    0                    0                   0                     1                   0               0               0               0               0               0               0               0               0                0                0                0                0                0                0                0                0                0                0                0                0                0                0                0                0                0             0             0             0             0             0             1             0             0   \n",
       "2       1  13.0              2              11                5                     13                 2                  0                    1              6          0         0       0              1                        0                 0            0                0                1                    0                    0                    0                    0                    0                   0                     1                   0               0               0               0               0               0               0               0               0                0                0                0                0                0                0                0                0                0                0                0                0                0                0                0                0                0             0             0             0             0             0             1             0             0   \n",
       "3       0  14.0              2              44                1                     16                 0                  0                    0              7          0         0       1              1                        0                 0            0                0                0                    0                    0                    0                    0                    0                   0                     1                   0               0               0               0               0               0               0               0               0                0                0                0                0                0                0                0                0                0                0                0                0                0                0                0                0                0             0             0             0             0             0             1             0             0   \n",
       "4       0  14.5              1              51                0                      8                 0                  0                    0              5          0         0       1              1                        0                 0            0                0                0                    0                    1                    0                    0                    0                   0                     0                   0               0               0               0               0               0               0               0               0                0                0                0                0                0                0                0                0                0                0                0                0                0                0                0                0                0             0             0             0             0             0             1             0             0   \n",
       "\n",
       "   penalty_id_10  penalty_id_11  penalty_id_13  penalty_id_14  penalty_id_17  penalty_id_20  penalty_id_22  penalty_id_25  foul_type_id_2  foul_type_id_3  foul_type_id_4  foul_type_id_5  foul_type_id_6  foul_type_id_7  foul_type_id_8  num_games_notperformed  num_tac_changes  num_tac_used  \n",
       "0              0              0              0              0              0              0              0              0               0               0               0               0               1               0               0                       0                0             0  \n",
       "1              0              0              0              0              0              0              0              0               0               0               0               0               0               0               0                       0                1             1  \n",
       "2              0              0              0              0              0              0              0              0               0               0               0               0               0               0               0                       3                0             1  \n",
       "3              0              0              0              0              0              0              0              0               0               0               0               0               0               0               0                       0                1             1  \n",
       "4              0              0              0              0              0              0              0              0               0               0               0               0               0               0               0                       0                0             2  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## After replacing these attbs some have almost 99% No so did not have significant information drop those columns.\n",
    "new_attbs = []\n",
    "for attb in attbs:\n",
    "    if data[attb].sum()<100:\n",
    "        col_temp=attb+'_temp'\n",
    "        data = data.drop(columns=[attb])\n",
    "        test = test.drop(columns=[attb])\n",
    "        data = data.drop(columns=[col_temp])\n",
    "        test = test.drop(columns=[col_temp])\n",
    "    else:\n",
    "        new_attbs.append(attb)\n",
    "attbs = new_attbs\n",
    "## Combine notpartof, injured and satout to have num_games_notperformed\n",
    "data['num_games_notperformed'] = data['num_games_notpartof'] + data['num_games_injured'] + data['num_games_satout']\n",
    "test['num_games_notperformed'] = test['num_games_notpartof'] + test['num_games_injured'] + test['num_games_satout']\n",
    "\n",
    "data['num_tac_changes'] = 0\n",
    "test['num_tac_changes'] = 0\n",
    "for col in attbs:\n",
    "    col_temp=col+'_temp'\n",
    "    data['num_tac_changes'] = data['num_tac_changes'] + data[col_temp]\n",
    "    data = data.drop(columns=[col_temp])\n",
    "    test['num_tac_changes'] = test['num_tac_changes'] + test[col_temp]\n",
    "    test = test.drop(columns=[col_temp])\n",
    "data['num_tac_used'] = 0\n",
    "test['num_tac_used'] = 0\n",
    "for col in attbs:\n",
    "    data['num_tac_used'] = data['num_tac_used'] + data[col]\n",
    "    data = data.drop(columns=[col])\n",
    "    test['num_tac_used'] = test['num_tac_used'] + test[col]\n",
    "    test = test.drop(columns=[col])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Any other Pre-processing Used. (Give the name along with the code.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "num_col = ['age', 'game_duration', 'num_game_moves', 'num_game_losses', 'num_practice_sessions', 'num_games_won',\\\n",
    "           'num_games_notpartof', 'num_games_injured', 'num_games_satout', 'num_games_notperformed', 'num_tac_changes',\\\n",
    "           'num_tac_used']\n",
    "for col in num_col:\n",
    "    skew_val = data[col].skew()\n",
    "    kurt_val = data[col].kurtosis()\n",
    "    if (abs(skew_val) >2) & (abs(kurt_val) >2):\n",
    "        if len(data[data[col] == 0])/len(data) <=0.02:\n",
    "            data = data[data[col] > 0]\n",
    "            data[col] = np.log(data[col])\n",
    "            #test[col] = np.log(test[col])\n",
    "            test[col] = np.log(test[col])\n",
    "        else:\n",
    "            data = data[data[col] >= 0]\n",
    "            data[col] = np.log1p(data[col])\n",
    "            #test[col] = np.log1p(test[col])\n",
    "            test[col] = np.log1p(test[col])\n",
    "\n",
    "# Standardize numeric columns\n",
    "m = np.mean(data[num_col], axis=0)\n",
    "std = np.std(data[num_col], axis=0)\n",
    "data[num_col] = (data[num_col] - m)/std\n",
    "#test[num_col] = (test[num_col] - np.mean(test[num_col], axis=0))/np.std(test[num_col], axis=0)\n",
    "test[num_col] = (test[num_col] - m)/std\n",
    "\n",
    "#Remove outliers\n",
    "data = data[(np.abs(stats.zscore(data[num_col])) < 3).all(axis=1)]\n",
    "\n",
    "#Reduction of feature that has more than 80% co-relation with any other feature\n",
    "data_temp = data.drop(['quidditch_league_player'], axis=1)\n",
    "corr_matrix = data_temp.corr().abs()\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.80)]\n",
    "data = data.drop(to_drop, axis=1)\n",
    "test = test.drop(to_drop, axis=1)\n",
    "print(\"Dataset shape:\", data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All columns are there\n"
     ]
    }
   ],
   "source": [
    "data_columns = list(data.columns)\n",
    "data_columns.remove('quidditch_league_player')\n",
    "test_columns = list(test.columns)\n",
    "if data_columns == test_columns:\n",
    "    print (\"All columns are there\")\n",
    "else:\n",
    "    for tc in test_columns:\n",
    "        data_columns.remove(tc)\n",
    "    print (\"There are some missing columns\",data_columns)\n",
    "\n",
    "    for missing in data_columns:\n",
    "        test[missing]=0\n",
    "\n",
    "data = data.sort_index(axis=1)\n",
    "test = test.sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## Replace game_move_id with groups found from applying kmeans, this way 26 features are reduced to k features\n",
    "from sklearn.cluster import KMeans\n",
    "lbl = data.groupby('game_move_id').mean()['quidditch_league_player']\n",
    "pre = np.array(lbl).reshape(26,1)\n",
    "#kmeans = KMeans(n_clusters=3).fit(pre)\n",
    "kmeans = KMeans(n_clusters=26,random_state=0).fit(pre)\n",
    "gmi_val2group = {}\n",
    "for t in data['game_move_id'].unique():\n",
    "    idx=t-1\n",
    "    if t>21:\n",
    "        idx=idx-1\n",
    "    if t>26:\n",
    "        idx=idx-1\n",
    "    print (t,\":\",kmeans.labels_[idx],end=\", \")\n",
    "    gmi_val2group[t]=kmeans.labels_[idx]\n",
    "    data.loc[data.game_move_id ==t, 'game_move_id'] = 'kmeans_'+str(kmeans.labels_[idx])\n",
    "    \n",
    "## One hot encode\n",
    "data = pd.concat([data,pd.get_dummies(data['game_move_id'], prefix='game_move')],axis=1)\n",
    "data = data.drop('game_move_id',axis=1)\n",
    "lbl = data.groupby('penalty_id').mean()['quidditch_league_player']\n",
    "pre = np.array(lbl).reshape(17,1)\n",
    "#kmeans = KMeans(n_clusters=4).fit(pre)\n",
    "kmeans = KMeans(n_clusters=17,random_state=0).fit(pre)\n",
    "pi_val2group = {}\n",
    "for t in data['penalty_id'].unique():\n",
    "    idx=t-1\n",
    "    if t>12:\n",
    "        idx=idx-1\n",
    "    if t>15:\n",
    "        idx=idx-2\n",
    "    if t>18:\n",
    "        idx=idx-2\n",
    "    if t>21:\n",
    "        idx=idx-1\n",
    "    if t>23:\n",
    "        idx=idx-2\n",
    "    print (t,\":\",kmeans.labels_[idx],end=\", \")\n",
    "    pi_val2group[t]=kmeans.labels_[idx]\n",
    "    data.loc[data.penalty_id ==t, 'penalty_id'] = 'kmeans_'+str(kmeans.labels_[idx])\n",
    "    \n",
    "data = pd.concat([data,pd.get_dummies(data['penalty_id'], prefix='penalty')],axis=1)\n",
    "data = data.drop('penalty_id',axis=1)\n",
    "lbl = data.groupby('foul_type_id').mean()['quidditch_league_player']\n",
    "pre = np.array(lbl).reshape(8,1)\n",
    "#kmeans = KMeans(n_clusters=4,random_state=0).fit(pre)\n",
    "kmeans = KMeans(n_clusters=8,random_state=0).fit(pre)\n",
    "fti_val2group = {}\n",
    "for t in data['foul_type_id'].unique():\n",
    "    idx=t-1\n",
    "    print (t,\":\",kmeans.labels_[idx],end=\", \")\n",
    "    fti_val2group[t]=kmeans.labels_[idx]\n",
    "    data.loc[data.foul_type_id ==t, 'foul_type_id'] = 'kmeans_'+str(kmeans.labels_[idx])\n",
    "\n",
    "data = pd.concat([data,pd.get_dummies(data['foul_type_id'], prefix='foul')],axis=1)\n",
    "data = data.drop('foul_type_id',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scale the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['quidditch_league_player']\n",
    "X = data.drop('quidditch_league_player',axis=1)\n",
    "X_test = test\n",
    "scaler = StandardScaler()\n",
    "scaler_all = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split train val and subsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split train and validation\n",
    "n = len(data)\n",
    "split = 0.2\n",
    "data_indices = np.arange(n)\n",
    "np.random.shuffle(data_indices)\n",
    "val_indices = data_indices[0:int(n*split)]\n",
    "train_indices = data_indices[int(n*split):]\n",
    "data_val = data.iloc[val_indices]\n",
    "data_train = data.iloc[train_indices]\n",
    "## Subsample so label 1 and label 0 has same number of instances\n",
    "rows_pos = data_train.quidditch_league_player == 1\n",
    "df_train_pos = data_train.loc[rows_pos]\n",
    "df_train_neg = data_train.loc[~rows_pos]\n",
    "neg_idx = np.arange(df_train_neg.shape[0])\n",
    "np.random.shuffle(neg_idx)\n",
    "sampled_idx = neg_idx[:len(df_train_pos)]\n",
    "data_train_sub = pd.concat([df_train_pos, df_train_neg.iloc[sampled_idx]],axis = 0)\n",
    "\n",
    "## Also subsample whole data like this, to be used on training the best model \n",
    "## after validation is done to pick the best hyperparameter. This way we use more data for test set and still \n",
    "## pick hyperparameters on unseen data.\n",
    "rows_pos = data.quidditch_league_player == 1\n",
    "df_pos = data.loc[rows_pos]\n",
    "df_neg = data.loc[~rows_pos]\n",
    "neg_idx = np.arange(df_neg.shape[0])\n",
    "np.random.shuffle(neg_idx)\n",
    "sampled_idx = neg_idx[:len(df_pos)]\n",
    "data_all = pd.concat([df_pos, df_neg.iloc[sampled_idx]],axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:7: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  import sys\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:13: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "y_train = data_train_sub['quidditch_league_player']\n",
    "X_train = data_train_sub.drop('quidditch_league_player',axis=1)\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "y_val = data_val['quidditch_league_player']\n",
    "X_val = data_val.drop('quidditch_league_player',axis=1)\n",
    "X_val = scaler.transform(X_val)\n",
    "\n",
    "y_all = data_all['quidditch_league_player']\n",
    "X_all = data_all.drop('quidditch_league_player',axis=1)\n",
    "X_all = scaler_all.fit_transform(X_all)\n",
    "\n",
    "X_test = scaler_all.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART II: Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1:\n",
    "Model Name: Logistic Regression<br>\n",
    "Evaluation method and metric used Name: Train-validation split, validation accuracy<br>\n",
    "Name of the Hyperparameter used: C,regularization term<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_search.py:271: UserWarning: The total space of parameters 9 is smaller than n_iter=20. Running 9 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 9 candidates, totalling 18 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed:    4.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.664\n",
      "F1 is 0.272\n",
      "Confusion matrix\n",
      "[[12116  5737]\n",
      " [ 1036  1264]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "clf = linear_model.LogisticRegression(C=1.,solver='newton-cg',penalty='l2')\n",
    "\n",
    "C = [0.0001,0.001, 0.01, 0.1, 1, 10, 100, 1000,10000]\n",
    "\n",
    "random_grid = {'C':C}\n",
    "\n",
    "rs_cv = RandomizedSearchCV(estimator = clf, param_distributions = random_grid, \n",
    "                               n_iter = 20, cv = 2, scoring=make_scorer(f1_score))\n",
    "rs_cv.fit(X_train, y_train)\n",
    "best_clf = rs_cv.best_estimator_\n",
    "y_pred = best_clf.predict(X_val)\n",
    "print(\"Accuracy is {0:.3f}\".format(accuracy_score(y_val, y_pred)))\n",
    "print(\"F1 is {0:.3f}\".format(f1_score(y_val, y_pred)))\n",
    "print (\"Confusion matrix\")\n",
    "print (confusion_matrix(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2:\n",
    "Model Name: MLP Classifier<br>\n",
    "Evaluation method and metric used Name: Train-validation split, accuracy score<br>\n",
    "Name of the Hyperparameter used: Hidden layer sizes,alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.603\n",
      "F1 is 0.266\n",
      "Confusion matrix\n",
      "[[10699  7154]\n",
      " [  847  1453]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf = MLPClassifier(hidden_layer_sizes=(3,3), activation='relu', solver='adam', alpha=1e-2,max_iter=1000)\n",
    "alpha = [1e-4,1e-3, 1e-2, 1e-1, 1, 10]\n",
    "solver = ['lbfgs','sgd','adam']\n",
    "activation = ['logistic','tanh','relu']\n",
    "hidden_layer_sizes = [(3,3),(5,5),(7,7),(9,9),(13,13),(20,20)]\n",
    "\n",
    "random_grid = {'alpha':alpha,\n",
    "               'solver':solver,\n",
    "               'activation':activation,\n",
    "               'hidden_layer_sizes':hidden_layer_sizes}\n",
    "\n",
    "rs_cv = RandomizedSearchCV(estimator = clf, param_distributions = random_grid, \n",
    "                           n_iter = 20, cv = 2, scoring=make_scorer(f1_score))\n",
    "rs_cv.fit(X_train, y_train)\n",
    "best_clf = rs_cv.best_estimator_\n",
    "y_pred = best_clf.predict(X_val)\n",
    "print(\"Accuracy is {0:.3f}\".format(accuracy_score(y_val, y_pred)))\n",
    "print(\"F1 is {0:.3f}\".format(f1_score(y_val, y_pred)))\n",
    "print (\"Confusion matrix\")\n",
    "print (confusion_matrix(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3:\n",
    "Model Name: Random Forests<br>\n",
    "Evaluation method and metric used Name: Train-validation split, validation accuracy <br>\n",
    "Name of the Hyperparameter used: max_depth,n_estimators,criterion<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.633\n",
      "F1 is 0.275\n",
      "Confusion matrix\n",
      "[[11360  6493]\n",
      " [  899  1401]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=100,max_depth=6, criterion = \"gini\", min_samples_split=6)\n",
    "n_estimators = range(200,1000,200)\n",
    "max_depth = range(1,20,1)\n",
    "min_samples_split = range(2,10,2)\n",
    "criterion = ['gini','entropy']\n",
    "\n",
    "random_grid = {'n_estimators':n_estimators,\n",
    "              'max_depth':max_depth,\n",
    "              'min_samples_split':min_samples_split,\n",
    "              'criterion':criterion}\n",
    "\n",
    "rs_cv = RandomizedSearchCV(estimator = clf, param_distributions = random_grid, \n",
    "                           n_iter = 20, cv = 2, scoring=make_scorer(f1_score))\n",
    "\n",
    "rs_cv.fit(X_train, y_train)\n",
    "best_clf = rs_cv.best_estimator_\n",
    "y_pred = best_clf.predict(X_val)\n",
    "print(\"Accuracy is {0:.3f}\".format(accuracy_score(y_val, y_pred)))\n",
    "print(\"F1 is {0:.3f}\".format(f1_score(y_val, y_pred)))\n",
    "print (\"Confusion matrix\")\n",
    "print (confusion_matrix(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART III: Best Hypothesis:\n",
    "Model Name:Random Forests<br>\n",
    "Reason:Has the highest f1 score<br>\n",
    "Hyper-parameter Value:## CLF HERE ##<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Fit the best classifier for the all subsampled dataset\n",
    "best_clf.fit(X_all,y_all)\n",
    "\n",
    "## Predict and upload test data\n",
    "test_result = pd.DataFrame()\n",
    "test_result['id_num']=pd.read_csv(\"./leaderboard_test.csv\")['id_num']\n",
    "test_result['quidditch_league_player'] = best_clf.predict(X_test)\n",
    "test_result['quidditch_league_player'] = test_result['quidditch_league_player'].replace({1:'YES',0:'NO'})\n",
    "test_result.to_csv('test_outputs.csv', sep=',',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
